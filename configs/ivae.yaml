# dataset
nps: 1000
ns: 10  # -> for a small amount of segments, StrNN seem to work better
dl: 5
dd: 5
nl: 2
s: 1
p: 'gauss'
act: 'xtanh'
uncentered: false
noisy: false
staircase: false
one_hot_labels: false
chain: false
use_sem: true

# IVAE with STRNNs work better (3+3 layers) vs vanilla iVAE w/ 5
# residual StrNNs help when labels are not one-hot
# for one-hot labels, the aux MLP needs more layers
# 100 is too wide for strnns, 40 works better
# non-residual aux works better than iVAE on non one-hot labels and SLIGHTLY better on one-hot labels
# for a chain, StrNN works faster, and is better with one-hot (non-one-hot is only faster, but same perf)
# model args
n_layers: 3
aux_net_layers: 3
strnn_layers: 3
strnn_width: 40
hidden_dim: 100
activation: 'xtanh'
ica: true
initialize: true
batch_norm: false
tcl: false
use_strnn: true
cond_strnn: false
separate_aux: true
residual_aux: false
ignore_u: false

# learning
a: 100
b: 1
c: 0
d: 10
gamma: 0
lr: 0.01
batch_size: 64
epochs: 20
no_scheduler: false
scheduler_tol: 3
anneal: false
anneal_epoch: 20
